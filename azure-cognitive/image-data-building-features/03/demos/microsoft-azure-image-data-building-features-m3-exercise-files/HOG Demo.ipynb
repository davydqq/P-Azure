{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Histogram of Ordered Gradients (HOG) Demo\n",
    "\n",
    "HOG first appeared in a patent application from Robert K. McConnell in 1981.  It was later leveraged by Mitsubishi Electric Research in 1994.  The current resurgence of HOG is primarily focused on a paper by Navneet Dalal & Bill Triggs presented at CVPR in 2005.  You can see the link to this paper below: \n",
    "\n",
    "Paper: [Histograms of Oriented Gradients for Human Detection](https://lear.inrialpes.fr/people/triggs/pubs/Dalal-cvpr05.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install\n",
    "\n",
    "We will install the following modules that will be used throughout this notebook.  Execute the following cell to install the needed dependencies.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install opencv-contrib-python==3.3.0.9 imutils scikit-image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports & Utility Functions\n",
    "\n",
    "Next, we will need to import libraries and add a utility function that we will use throughout the notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "from skimage.feature import hog\n",
    "from skimage import data, exposure, io\n",
    "from imutils.object_detection import non_max_suppression\n",
    "from enum import Enum\n",
    "\n",
    "class ImageColor(Enum):\n",
    "    GRAYSCALE = 0\n",
    "    DEFAULT = 1\n",
    "    BGR = 2\n",
    "\n",
    "# This is a utility function that we will use to display images throughout the notebook\n",
    "def showImage(cv_image, image_color, title = ''):\n",
    "    plt.figure(figsize=(20,20))\n",
    "    if image_color == ImageColor.GRAYSCALE:\n",
    "        plt.imshow(cv_image, cmap = plt.cm.gray)\n",
    "    elif image_color == ImageColor.BGR:\n",
    "        plt.imshow(cv.cvtColor(cv_image, cv.COLOR_BGR2RGB))\n",
    "    else:\n",
    "        plt.imshow(cv_image)\n",
    "    if title:\n",
    "        plt.title(title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Our Objective\n",
    "\n",
    "We will be working to accomplish two primary tasks: visualizing the HOG feature vector for a specific image, and utilizing the included person detector in OpenCV to see HOG at work. For the visualization of the HOG feature vector we will be leveraging `scikit-image`. \n",
    "\n",
    "Learn More: [scikit-image](https://scikit-image.org/)\n",
    "\n",
    "![Person Image](person1.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing HOG\n",
    "\n",
    "In the following example, we will utilize a feature of `scikit-image` to visualize the Histogram of Ordered Gradients feature vector for the entire image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_hog(filename):\n",
    "    # Read the image into a format scikit-image can work with\n",
    "    image = io.imread(filename)\n",
    "    \n",
    "    # scikit-image HOG parameters\n",
    "    orientations = 8\n",
    "    pixels_per_cell = (16,16)\n",
    "    cells_per_block=(1, 1)\n",
    "    \n",
    "    # Get vector and HOG image\n",
    "    feature_vector, hog_image = hog(image,\n",
    "                                    orientations=orientations,\n",
    "                                    pixels_per_cell=pixels_per_cell,\n",
    "                                    cells_per_block=cells_per_block,\n",
    "                                    visualize=True,\n",
    "                                    multichannel=True)\n",
    "    \n",
    "    # Rescale intensity based on vector values\n",
    "    hog_image_rescaled = exposure.rescale_intensity(hog_image, in_range=(0, 10))\n",
    "    \n",
    "    # Show images\n",
    "    showImage(image, False, 'Original Image')\n",
    "    showImage(hog_image_rescaled, ImageColor.GRAYSCALE, 'Histogram of Ordered Gradients Image')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now utilize this function to visualize the feature vector for this image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_hog('person1.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detecting People\n",
    "\n",
    "Up to this point, we have leveraged a non-learning based approach for the images we are analyzing.  This next objective will bridge the gap between the non-learning and the learning based approach.  OpenCV includes a person detector.  This detector utilizes HOD vectors for analysis, but it includes a pre-trained Linear Support Vector Machine (SVN) model. \n",
    "\n",
    "This is an example that illustrates how we can use the outputs of algorithms from a non-learning approach to train a model using a learning based approach.\n",
    "\n",
    "Given the training data that would be needed to train our own model, we will instead use the included detector from OpenCV."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now create a function that will attempt to detect people in the images was pass into it.  We will use this function to analyze this functionality across multiple images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_people(filename):\n",
    "    # Setup HOG and detector\n",
    "    hog_cv = cv.HOGDescriptor()\n",
    "    hog_cv.setSVMDetector(cv.HOGDescriptor_getDefaultPeopleDetector())\n",
    "\n",
    "    # Get image in a format OpenCV can work with\n",
    "    image = cv.imread(filename)\n",
    "    \n",
    "    # HOG Detector Parameters\n",
    "    stride = (4, 4)\n",
    "    padding = (8, 8)\n",
    "    scale = 1.05\n",
    "\n",
    "    # Get detected weights and rects for matches\n",
    "    rects, weights = hog_cv.detectMultiScale(image,\n",
    "                                             winStride=stride,\n",
    "                                             padding=padding,\n",
    "                                             scale=scale)\n",
    "\n",
    "    # Convert xywh to xyxy rects for suppression function\n",
    "    converted_rects = np.array([[x, y, x + w, y + h] for (x, y, w, h) in rects])\n",
    "\n",
    "    # Suppress all rects that are contained within another rect\n",
    "    final_matches = non_max_suppression(converted_rects,\n",
    "                                        probs=None,\n",
    "                                        overlapThresh=0.65)\n",
    "\n",
    "    # Draw a Rectangle around the detected people\n",
    "    rect_color = (0, 255, 0)\n",
    "    for (xA, yA, xB, yB) in final_matches:\n",
    "        cv.rectangle(image,\n",
    "                     (xA, yA),\n",
    "                     (xB, yB),\n",
    "                     rect_color,\n",
    "                     2)\n",
    "    \n",
    "    # Show the image with drawn rects\n",
    "    num_matches = len(final_matches)\n",
    "    showImage(image, ImageColor.BGR, f\"{num_matches} Detected Person{'s' if num_matches > 1 else ''}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detect_people('person1.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now define a function that allows us to wrap the HOG visualization and the person detection into a single call:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_detect_people(filename):\n",
    "    visualize_hog(filename)\n",
    "    detect_people(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_detect_people('people1.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_detect_people('people2.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 - AzureML",
   "language": "python",
   "name": "python3-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
